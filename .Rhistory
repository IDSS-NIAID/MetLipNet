#### Package Installation ####
# run this chunk to install packages to your local machine
devtools::install_github("IDSS-NIAID/MetLipNet")
?cal_met_cor
#' @examples
#' \dontrun{
#'   library(igraph)
#'   g <- erdos.renyi.game(100, p = 0.05)  # Generate a random network
#'   result <- optimize_network_layout(g, spread_factor = 1.5)
#'   plot(result$plot)
#'   plot(g, layout = result$layout)
#' }
#'
#' @export
optimize_network_layout <- function(g, n_samples = 50, n_bootstrap = 10, spread_factor = 1, xgb_depth = 3, xgb_eta = 0.3, xgb_nrounds = 20, verbose = TRUE, seed = 31415926) {
library(ggplot2)
layouts <- list(
"fr" = igraph::layout_with_fr,
"kk" = igraph::layout_with_kk,
"lgl" = function(g) {
if (!igraph::is_connected(g)) {
message("Graph is disconnected. Falling back to Kamada-Kawai layout.")
return(igraph::layout_with_kk(g))
} else {
return(igraph::layout_with_lgl(g, maxiter = 100))
}
}
)
parameters <- tibble(
layout = sample(names(layouts), n_samples, replace = TRUE)
) %>% split(1:n_samples)
total_samples <- length(parameters)
plan(multisession)
results <- furrr::future_map(seq_along(parameters), function(i) {
param <- parameters[[i]]
layout_fn <- layouts[[param$layout]]
if (verbose) {
message(sprintf("[Optimization %d/%d] Running %s layout", i, total_samples, param$layout))
}
g_layout <- layout_fn(g) * spread_factor
# Additional network feature: average node distance
avg_distance <- mean(dist(g_layout))
# Bootstrapping stress values
stress_values <- replicate(n_bootstrap, {
sampled_nodes <- sample(1:nrow(g_layout), size = round(0.8 * nrow(g_layout)), replace = TRUE)
sum(dist(g_layout[sampled_nodes, ])^2)
})
stress_value <- mean(stress_values, na.rm = TRUE)
if (is.nan(stress_value) || is.infinite(stress_value)) stress_value <- 0
# Validate stress value before training XGBoost
if (length(unique(parameters$layout)) < 2 || stress_value == 0) {
return(list(layout = g_layout, stress = stress_value, stress_values = stress_values))
}
# Train XGBoost model only on valid values with additional features
train_data <- data.frame(layout = as.numeric(factor(param$layout)), stress = stress_value, avg_distance = avg_distance)
dtrain <- xgb.DMatrix(data = as.matrix(train_data[, -1]), label = train_data$layout)
xgb_model <- xgboost(data = dtrain, max.depth = xgb_depth, eta = xgb_eta, nrounds = xgb_nrounds, objective = "multi:softmax", num_class = length(layouts), verbose = 0)
predicted_layout <- predict(xgb_model, dtrain)
if (verbose) {
message(sprintf("[Optimization %d/%d] Completed %s layout | Stress: %.2f | Avg Distance: %.2f | Predicted Best: %s\n", i, total_samples, param$layout, stress_value, avg_distance, names(layouts)[predicted_layout + 1]))
}
list(layout = g_layout, stress = stress_value, stress_values = stress_values, predicted_layout = names(layouts)[predicted_layout + 1])
}, .options = furrr_options(seed = 31415926))
future::plan(sequential)
results_df <- bind_rows(results)
best_result <- results[[which.min(sapply(results, function(x) x$stress))]]
stress_df <- data.frame(Bootstrap_Iteration = 1:n_bootstrap, Stress_Value = best_result$stress_values)
stress_plot <- ggplot(stress_df, aes(x = Bootstrap_Iteration, y = Stress_Value)) +
geom_line() +
geom_point() +
labs(title = "Bootstrapped Stress Value Across Iterations", x = "Bootstrap Iteration", y = "Stress Value") +
theme_minimal()
return(list(layout = best_result$layout, stress_values = best_result$stress_values, plot = stress_plot))
}
# run this chunk to open libraries containing functions to execute the script
library(MetLipNet)
library(future)
library(ggraph)
library(openxlsx)
library(dplyr)
library(future)
library(furrr)
library(RColorBrewer)
library(tidyverse)
library(corrr)
library(igraph)
library(ggplot2)
library(rstatix)
dat <-read.csv("Gwen_GiGi_CleanedData.csv")
dat_longer <- dat %>%
tidyr::pivot_longer(cols = 4:ncol(dat), names_to = "condition", values_to = "Value_raw") %>%
filter(Class != "LM") %>%
select(-Shape, -Class)
dat_scaled <- dat %>%
tidyr::pivot_longer(cols = 4:ncol(dat), names_to = "Sample", values_to = "Value_raw") %>%
group_by(Metabolite) %>%
mutate(Value_scaled = as.numeric(scale(Value_raw, center=TRUE, scale=TRUE))) %>%
ungroup() %>%
select(-Value_raw) %>%
tidyr::pivot_wider(id_cols = 1:3, names_from = Sample, values_from = Value_scaled)
# view the help page
?cal_met_cor
# The returned data frame will be ready for the igraph function.
dat_cor_result <- MetLipNet::cal_met_cor(dat_longer, intensity_col = "Value_raw", identifier_col = "Metabolite")
# modify the correlation result data frame for attributes that apply to metabolite pairs
dat_igraph <- dat_cor_result %>%
filter(p_value < 0.01) %>%
mutate(edge_color = case_when(estimate < 0 ~ "estimate>0",
estimate > 0 ~ "estimate<0",
TRUE ~ "grey"))
# modify the correlation result data frame for attributes that apply to metabolite pairs
dat_igraph <- dat_cor_result %>%
filter(p_value < 0.01) %>%
mutate(edge_color = case_when(estimate < 0 ~ "estimate>0",
estimate > 0 ~ "estimate<0",
TRUE ~ "grey"))
# This creates the network object which can be modified from here
g <- igraph::graph_from_data_frame(dat_igraph, directed = FALSE)
# function that relies on bootsrap sampling and XGBoost to predict the best layout
best_layout <- optimize_network_layout(g)
#### Correlation Data Export ####
#write.csv(R_Data_Corr, file="Notarangelo0001 R vals pearson all v all.csv")#Option to write the R matrix to a csv. You can do the same thing for the p values for handling elsewhere if needed.
write.csv(dat_cor_result, file="dat_cor_result.csv", row.names = F)
library(dplyr)
library(rstatix)
library(corrr)
library(foreach)
library(doParallel)
cal_met_cor <- function(data, intensity_col = "intensity", identifier_col = "metabolite", method = "pearson", remove_na = TRUE, p_threshold = NULL, n_cores = parallel::detectCores() - 1) {
if (nrow(data) < 2) {
return(tibble(from = character(), to = character(), estimate = numeric(), p_value = numeric()))
}
metadata_cols <- setdiff(names(data), c(intensity_col, identifier_col))
if (!(identifier_col %in% names(data))) {
stop(paste("Identifier column", identifier_col, "not found in dataset"))
}
intensity_wide <- data %>%
pivot_wider(names_from = identifier_col, values_from = intensity_col)
if (remove_na) {
intensity_wide <- intensity_wide %>% drop_na()
}
if (ncol(intensity_wide) < 3) {
warning("Not enough metabolites for correlation. Returning empty data frame.")
return(tibble(from = character(), to = character(), estimate = numeric(), p_value = numeric()))
}
numeric_cols <- intensity_wide %>% select(where(is.numeric))
registerDoParallel(n_cores)
cor_results <- foreach(i = 1:(ncol(numeric_cols) - 1), .combine = bind_rows, .packages = c("dplyr", "rstatix")) %dopar% {
results <- tibble()
for (j in (i + 1):ncol(numeric_cols)) {
cor_test <- cor_test(numeric_cols[, i], numeric_cols[, j], method = method)
results <- bind_rows(results, tibble(from = names(numeric_cols)[i], to = names(numeric_cols)[j], estimate = cor_test$cor, p_value = cor_test$p))
}
results
}
stopImplicitCluster()
if (!is.null(p_threshold)) {
cor_results <- cor_results %>% filter(p_value <= p_threshold)
}
return(cor_results)
}
library(ggraph)
library(igraph)
#' @examples
#' \dontrun{
#'   library(igraph)
#'   g <- erdos.renyi.game(100, p = 0.05)  # Generate a random network
#'   result <- optimize_network_layout(g, spread_factor = 1.5)
#'   plot(result$plot)
#'   plot(g, layout = result$layout)
#' }
#'
#' @export
optimize_network_layout <- function(g, n_samples = 50, n_bootstrap = 10, spread_factor = 1, xgb_depth = 3, xgb_eta = 0.3, xgb_nrounds = 20, verbose = TRUE, seed = 31415926) {
library(ggplot2)
layouts <- list(
"fr" = igraph::layout_with_fr,
"kk" = igraph::layout_with_kk,
"lgl" = function(g) {
if (!igraph::is_connected(g)) {
message("Graph is disconnected. Falling back to Kamada-Kawai layout.")
return(igraph::layout_with_kk(g))
} else {
return(igraph::layout_with_lgl(g, maxiter = 100))
}
}
)
parameters <- tibble(
layout = sample(names(layouts), n_samples, replace = TRUE)
) %>% split(1:n_samples)
total_samples <- length(parameters)
plan(multisession)
results <- furrr::future_map(seq_along(parameters), function(i) {
param <- parameters[[i]]
layout_fn <- layouts[[param$layout]]
if (verbose) {
message(sprintf("[Optimization %d/%d] Running %s layout", i, total_samples, param$layout))
}
g_layout <- layout_fn(g) * spread_factor
# Additional network feature: average node distance
avg_distance <- mean(dist(g_layout))
# Bootstrapping stress values
stress_values <- replicate(n_bootstrap, {
sampled_nodes <- sample(1:nrow(g_layout), size = round(0.8 * nrow(g_layout)), replace = TRUE)
sum(dist(g_layout[sampled_nodes, ])^2)
})
stress_value <- mean(stress_values, na.rm = TRUE)
if (is.nan(stress_value) || is.infinite(stress_value)) stress_value <- 0
# Validate stress value before training XGBoost
if (length(unique(parameters$layout)) < 2 || stress_value == 0) {
return(list(layout = g_layout, stress = stress_value, stress_values = stress_values))
}
# Train XGBoost model only on valid values with additional features
train_data <- data.frame(layout = as.numeric(factor(param$layout)), stress = stress_value, avg_distance = avg_distance)
dtrain <- xgb.DMatrix(data = as.matrix(train_data[, -1]), label = train_data$layout)
xgb_model <- xgboost(data = dtrain, max.depth = xgb_depth, eta = xgb_eta, nrounds = xgb_nrounds, objective = "multi:softmax", num_class = length(layouts), verbose = 0)
predicted_layout <- predict(xgb_model, dtrain)
if (verbose) {
message(sprintf("[Optimization %d/%d] Completed %s layout | Stress: %.2f | Avg Distance: %.2f | Predicted Best: %s\n", i, total_samples, param$layout, stress_value, avg_distance, names(layouts)[predicted_layout + 1]))
}
list(layout = g_layout, stress = stress_value, stress_values = stress_values, predicted_layout = names(layouts)[predicted_layout + 1])
}, .options = furrr_options(seed = 31415926))
future::plan(sequential)
results_df <- bind_rows(results)
best_result <- results[[which.min(sapply(results, function(x) x$stress))]]
stress_df <- data.frame(Bootstrap_Iteration = 1:n_bootstrap, Stress_Value = best_result$stress_values)
stress_plot <- ggplot(stress_df, aes(x = Bootstrap_Iteration, y = Stress_Value)) +
geom_line() +
geom_point() +
labs(title = "Bootstrapped Stress Value Across Iterations", x = "Bootstrap Iteration", y = "Stress Value") +
theme_minimal()
return(list(layout = best_result$layout, stress_values = best_result$stress_values, plot = stress_plot))
}
#'   g <- erdos.renyi.game(100, p = 0.05)  # Generate a random network
#'   result <- optimize_network_layout(g, spread_factor = 1.5)
#'   best_layout <- result$best_layout
#'   stress_values <- result$stress_values
#'   stress_plot <- result$stress_plot
#'   plot(stress_plot)
#'   plot(g, layout = best_layout)
#' }
#'
#' @export
optimize_network_layout <- function(g, n_samples = 50, n_bootstrap = 10, spread_factor = 1, xgb_depth = 3, xgb_eta = 0.3, xgb_nrounds = 20, verbose = TRUE, seed = 31415926) {
library(ggplot2)
layouts <- list(
"fr" = igraph::layout_with_fr,
"kk" = igraph::layout_with_kk,
"lgl" = function(g) {
if (!igraph::is_connected(g)) {
message("Graph is disconnected. Falling back to Kamada-Kawai layout.")
return(igraph::layout_with_kk(g))
} else {
return(igraph::layout_with_lgl(g, maxiter = 100))
}
}
)
parameters <- tibble(
layout = sample(names(layouts), n_samples, replace = TRUE)
) %>% split(1:n_samples)
total_samples <- length(parameters)
plan(multisession)
results <- furrr::future_map(seq_along(parameters), function(i) {
param <- parameters[[i]]
layout_fn <- layouts[[param$layout]]
if (verbose) {
message(sprintf("[Optimization %d/%d] Running %s layout", i, total_samples, param$layout))
}
g_layout <- layout_fn(g) * spread_factor
# Ensure layout has correct dimensions
if (nrow(g_layout) != vcount(g)) {
stop("Error: Layout dimensions do not match the number of graph nodes.")
}
# Additional network feature: average node distance
avg_distance <- mean(dist(g_layout))
# Bootstrapping stress values
stress_values <- replicate(n_bootstrap, {
sampled_nodes <- sample(1:nrow(g_layout), size = round(0.8 * nrow(g_layout)), replace = TRUE)
sum(dist(g_layout[sampled_nodes, ])^2)
})
stress_value <- mean(stress_values, na.rm = TRUE)
if (is.nan(stress_value) || is.infinite(stress_value)) stress_value <- 0
list(layout = g_layout, stress = stress_value, stress_values = stress_values)
}, .options = furrr_options(seed = 31415926))
future::plan(sequential)
# Extract best result
best_result_index <- which.min(sapply(results, function(x) x$stress))
best_result <- results[[best_result_index]]
# Ensure best layout is correctly formatted
best_layout <- as.matrix(best_result$layout)
rownames(best_layout) <- NULL
stress_df <- data.frame(Bootstrap_Iteration = 1:n_bootstrap, Stress_Value = best_result$stress)
stress_plot <- ggplot(stress_df, aes(x = Bootstrap_Iteration, y = Stress_Value)) +
geom_line() +
geom_point() +
labs(title = "Bootstrapped Stress Value Across Iterations", x = "Bootstrap Iteration", y = "Stress Value") +
theme_minimal()
# Return multiple objects separately
invisible(list(best_layout = best_layout, stress_values = best_result$stress, stress_plot = stress_plot))
}
# function that relies on bootsrap sampling and XGBoost to predict the best layout
best_layout <- optimize_network_layout(g)
attributes <- dat %>%
select(Metabolite, Class, Shape)
# modify node attributes
nodes <- tibble(Metabolite = V(g)$name) %>%
left_join(attributes, join_by(Metabolite))
V(g)$Class <- nodes$Class
V(g)$Shape <- nodes$Shape
# generate the plot
p <- ggraph(g, layout = best_layout) +
geom_edge_link(aes(color = edge_color, linewidth = p_value), alpha = 0.8) +
geom_node_point(size = 6, aes(color = Class, shape = Shape)) +
geom_node_text(aes(label = name), repel = TRUE) +
scale_edge_color_manual(values = c("purple", "goldenrod"))+
scale_color_brewer(palette = "Dark2")
View(best_layout)
best_layout <- best_result$best_layout
# function that relies on bootsrap sampling and XGBoost to predict the best layout
best_result <- optimize_network_layout(g)
best_layout <- best_result$best_layout
attributes <- dat %>%
select(Metabolite, Class, Shape)
# modify node attributes
nodes <- tibble(Metabolite = V(g)$name) %>%
left_join(attributes, join_by(Metabolite))
V(g)$Class <- nodes$Class
V(g)$Shape <- nodes$Shape
# generate the plot
p <- ggraph(g, layout = best_layout) +
geom_edge_link(aes(color = edge_color, linewidth = p_value), alpha = 0.8) +
geom_node_point(size = 6, aes(color = Class, shape = Shape)) +
geom_node_text(aes(label = name), repel = TRUE) +
scale_edge_color_manual(values = c("purple", "goldenrod"))+
scale_color_brewer(palette = "Dark2")
# view the plot
plot(p)
# function that relies on bootsrap sampling and XGBoost to predict the best layout
best_result <- optimize_network_layout(g, spread_factor = 5)
best_layout <- best_result$best_layout
attributes <- dat %>%
select(Metabolite, Class, Shape)
# modify node attributes
nodes <- tibble(Metabolite = V(g)$name) %>%
left_join(attributes, join_by(Metabolite))
V(g)$Class <- nodes$Class
V(g)$Shape <- nodes$Shape
# generate the plot
p <- ggraph(g, layout = best_layout) +
geom_edge_link(aes(color = edge_color, linewidth = p_value), alpha = 0.8) +
geom_node_point(size = 6, aes(color = Class, shape = Shape)) +
geom_node_text(aes(label = name), repel = TRUE) +
scale_edge_color_manual(values = c("purple", "goldenrod"))+
scale_color_brewer(palette = "Dark2")
# view the plot
plot(p)
cal_met_cor <- function(data, intensity_col = "intensity", identifier_col = "metabolite", method = "pearson", remove_na = TRUE, p_threshold = NULL, n_cores = parallel::detectCores() - 1) {
if (nrow(data) < 2) {
return(tibble(from = character(), to = character(), estimate = numeric(), p_value = numeric()))
}
metadata_cols <- setdiff(names(data), c(intensity_col, identifier_col))
if (!(identifier_col %in% names(data))) {
stop(paste("Identifier column", identifier_col, "not found in dataset"))
}
intensity_wide <- data %>%
pivot_wider(names_from = identifier_col, values_from = intensity_col)
if (remove_na) {
intensity_wide <- intensity_wide %>% drop_na()
}
if (ncol(intensity_wide) < 3) {
warning("Not enough metabolites for correlation. Returning empty data frame.")
return(tibble(from = character(), to = character(), estimate = numeric(), p_value = numeric()))
}
numeric_cols <- intensity_wide %>% select(where(is.numeric))
registerDoParallel(n_cores)
cor_results <- foreach(i = 1:(ncol(numeric_cols) - 1), .combine = bind_rows, .packages = c("dplyr", "rstatix")) %dopar% {
results <- tibble()
for (j in (i + 1):ncol(numeric_cols)) {
cor_test <- cor_test(numeric_cols[, i], numeric_cols[, j], method = method)
results <- bind_rows(results, tibble(from = names(numeric_cols)[i], to = names(numeric_cols)[j], estimate = cor_test$cor, p_value = cor_test$p))
}
results
}
stopImplicitCluster()
if (!is.null(p_threshold)) {
cor_results <- cor_results %>% filter(p_value <= p_threshold)
}
return(cor_results)
}
# The returned data frame will be ready for the igraph function.
dat_cor_result <- cal_met_cor(dat_longer, intensity_col = "Value_raw", identifier_col = "Metabolite")
# function that relies on bootsrap sampling and XGBoost to predict the best layout
best_result <- optimize_network_layout(g, spread_factor = 50)
best_layout <- best_result$best_layout
attributes <- dat %>%
select(Metabolite, Class, Shape)
# modify node attributes
nodes <- tibble(Metabolite = V(g)$name) %>%
left_join(attributes, join_by(Metabolite))
V(g)$Class <- nodes$Class
V(g)$Shape <- nodes$Shape
# generate the plot
p <- ggraph(g, layout = best_layout) +
geom_edge_link(aes(color = edge_color, linewidth = p_value), alpha = 0.8) +
geom_node_point(size = 6, aes(color = Class, shape = Shape)) +
geom_node_text(aes(label = name), repel = TRUE) +
scale_edge_color_manual(values = c("purple", "goldenrod"))+
scale_color_brewer(palette = "Dark2")
# view the plot
plot(p)
library(devtools)
setwd("~/GitHub/Untargeted-Metabolomics-Network-Analysis")
roxygen2::roxygenise()
roxygen2::roxygenise()
# run this line every time there is an update to the MetLipNet package
devtools::install_github("IDSS-NIAID/MetLipNet")
